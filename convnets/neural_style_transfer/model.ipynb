{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0-dev20191121\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage.io as image\n",
    "from skimage.transform import resize\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_image = image.imread('./images/monet.jpg')\n",
    "content_image = image.imread('./images/louvre.jpg')\n",
    "\n",
    "content_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape image to mach expected input of VGG16\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3)) \n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    image = image - MEANS\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-123.58196078, -116.54370588, -103.48409804],\n",
       "         [-123.58196078, -116.53978431, -103.47853713],\n",
       "         [-123.58109316, -116.53226288, -103.46641857],\n",
       "         ...,\n",
       "         [-123.59086467, -116.59574703, -103.57853739],\n",
       "         [-123.58980392, -116.59574703, -103.58213725],\n",
       "         [-123.58980392, -116.59860784, -103.58213725]],\n",
       "\n",
       "        [[-123.58196078, -116.54360286, -103.48399502],\n",
       "         [-123.57989118, -116.53947526, -103.47461556],\n",
       "         [-123.57803922, -116.52920894, -103.45902572],\n",
       "         ...,\n",
       "         [-123.58758678, -116.59076471, -103.57133766],\n",
       "         [-123.58980392, -116.59437722, -103.57398506],\n",
       "         [-123.58632578, -116.5980614 , -103.57429412]],\n",
       "\n",
       "        [[-123.58196078, -116.53978431, -103.48101221],\n",
       "         [-123.57803922, -116.53586275, -103.47069399],\n",
       "         [-123.57803922, -116.52528737, -103.45510415],\n",
       "         ...,\n",
       "         [-123.58980392, -116.58684314, -103.57037255],\n",
       "         [-123.5869439 , -116.59076471, -103.57037255],\n",
       "         [-123.58588235, -116.59413983, -103.57156214]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-123.37218953, -116.47903267, -103.68609149],\n",
       "         [-123.39842247, -116.5052656 , -103.71232443],\n",
       "         [-123.3817666 , -116.48902893, -103.69120318],\n",
       "         ...,\n",
       "         [-123.47469624, -116.58546095, -103.75330408],\n",
       "         [-123.47157906, -116.5901869 , -103.75224254],\n",
       "         [-123.46604977, -116.58857918, -103.74857918]],\n",
       "\n",
       "        [[-123.39056879, -116.49741193, -103.70447075],\n",
       "         [-123.36696692, -116.47381006, -103.68086888],\n",
       "         [-123.3459948 , -116.45402727, -103.65443228],\n",
       "         ...,\n",
       "         [-123.48045002, -116.58899758, -103.76076228],\n",
       "         [-123.47666941, -116.59394696, -103.76238108],\n",
       "         [-123.4818965 , -116.60442591, -103.77152973]],\n",
       "\n",
       "        [[-123.289566  , -116.39746989, -103.60306933],\n",
       "         [-123.33072904, -116.43923708, -103.64401367],\n",
       "         [-123.39562278, -116.50519815, -103.7067925 ],\n",
       "         ...,\n",
       "         [-123.48180006, -116.58983253, -103.76265799],\n",
       "         [-123.48906461, -116.60375088, -103.77551559],\n",
       "         [-123.49623272, -116.61429412, -103.78605882]]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_image = resize(content_image, (244, 244))\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "# content_image.shape\n",
    "\n",
    "style_image = resize(style_image, (244, 244))\n",
    "style_image = reshape_and_normalize_image(style_image)\n",
    "\n",
    "\n",
    "m, n_h, n_W, n_C = content_image.shape\n",
    "# content_image = tf.reshape(content_image, shape=[m, n_h, n_W, n_C])\n",
    "content_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = 0.6):\n",
    "    \"\"\"\n",
    "    Generates a noisy image by adding random noise to the content_image\n",
    "    \"\"\"\n",
    "    \n",
    "    IMAGE_WIDTH = 244\n",
    "    IMAGE_HEIGHT = 244\n",
    "    COLOR_CHANNELS = 3\n",
    "    \n",
    "    # Generate a random noise_image\n",
    "    noise_image = np.random.uniform(-20, 20, (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')\n",
    "    \n",
    "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    \n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_conv4\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_conv4\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_conv4\n",
      "block5_pool\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_tensor=tf.keras.Input(shape=(224, 224, 3)))\n",
    "model.trainable = False\n",
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layers = ['block4_conv2']\n",
    "\n",
    "style_layers = [('block1_conv1', 0.2), \n",
    "                ('block2_conv1', 0.2), \n",
    "                ('block3_conv1', 0.2), \n",
    "                ('block4_conv1', 0.2), \n",
    "                ('block5_conv1', 0.2)]\n",
    "style_layers = ['block1_conv1', \n",
    "                'block2_conv1', \n",
    "                'block3_conv1', \n",
    "                'block4_conv1', \n",
    "                'block5_conv1']\n",
    "\n",
    "\n",
    "content_outputs = [model.get_layer(name).output for name in content_layers]\n",
    "style_outputs = [model.get_layer(name).output for name in style_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_input = tf.keras.applications.vgg19.preprocess_input(content_image)\n",
    "style_input = tf.keras.applications.vgg19.preprocess_input(style_image)\n",
    "generated_input = tf.keras.applications.vgg19.preprocess_input(generated_image)\n",
    "\n",
    "a_content = tf.keras.Model([model.input], outputs = content_outputs, name='VGG19')\n",
    "a_style = tf.keras.Model(inputs=[model.input], outputs = style_outputs, name='VGG19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Support Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_C_unrolled = tf.reshape(a_C, shape=[m, n_H*n_W, n_C])\n",
    "    a_G_unrolled = tf.reshape(a_G, shape=[m, n_H*n_W, n_C])\n",
    "    \n",
    "    content_cost = 1/(4*n_H*n_W*n_C) * tf.reduce_sum(tf.square(a_C_unrolled - a_G_unrolled))\n",
    "    \n",
    "    return content_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_content = \n",
      "7.056877\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "a_C = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "a_G = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "print(\"J_content = \\n\" + str(J_content.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    return tf.matmul(A, tf.transpose(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA = \n",
      "[[ 63.1888    -26.721275   -7.7320204]\n",
      " [-26.721275   12.76758    -2.5158243]\n",
      " [ -7.7320204  -2.5158243  23.752384 ]]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "A = tf.random.normal([3, 2*1], mean=1, stddev=4)\n",
    "GA = gram_matrix(A)\n",
    "print(\"GA = \\n\" + str(GA.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost_layer(a_S, a_G):\n",
    "    \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_S_unrolled = tf.reshape(tf.transpose(a_S, perm=[0, 3, 1, 2]), shape=[n_C, n_H*n_W])\n",
    "    a_G_unrolled = tf.reshape(tf.transpose(a_G, perm=[0, 3, 1, 2]), shape=[n_C, n_H*n_W])\n",
    "    \n",
    "    GS = gram_matrix(a_S_unrolled)\n",
    "    GG = gram_matrix(a_G_unrolled)\n",
    "    \n",
    "    layer_style_cost = 1/(4*(n_C**2)*(n_H*n_W)**2) * tf.reduce_sum(tf.square(GS - GG))\n",
    "    return layer_style_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_style_layer = 14.017808\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "a_S = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "a_G = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "J_style_layer = compute_style_cost_layer(a_S, a_G)\n",
    "\n",
    "print(\"J_style_layer = \" + str(J_style_layer.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(style_input, generated_input, style_layers, coefs):\n",
    "    \n",
    "    style_cost = 0\n",
    "    style_outputs = a_style(style_input)\n",
    "    generated_outputs = a_style(generated_input)\n",
    "    \n",
    "    for i in range(0, len(style_outputs)):\n",
    "        \n",
    "        a_S = style_outputs[i]\n",
    "        a_G = generated_outputs[i]\n",
    "        \n",
    "        layer_cost = compute_style_cost_layer(a_S, a_G)\n",
    "        style_cost += (coefs[i] * layer_cost)\n",
    "    \n",
    "    return style_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(content_cost, style_cost, alpha = 10, beta = 10):\n",
    "    total_cost = (alpha * content_cost) + (beta * style_cost)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 22.251383239423077\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "np.random.seed(3)\n",
    "J_content = np.random.randn()    \n",
    "J_style = np.random.randn()\n",
    "J = total_cost(J_content, J_style)\n",
    "print(\"J = \" + str(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float64) for input (None, 224, 224, 3), but it was re-called on a Tensor with incompatible shape (1, 244, 244, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float64) for input (None, 224, 224, 3), but it was re-called on a Tensor with incompatible shape (1, 244, 244, 3).\n",
      "\n",
      "J_content = 371415.31348055525\n"
     ]
    }
   ],
   "source": [
    "content_output = a_content(content_input)\n",
    "generated_output = a_content(generated_input)\n",
    "\n",
    "J_content = compute_content_cost(content_output, generated_output)\n",
    "print(\"\\nJ_content = \" + str(J_cost.numpy()))\n",
    "# style_output = a_style(style_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float64) for input (None, 224, 224, 3), but it was re-called on a Tensor with incompatible shape (1, 244, 244, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float64) for input (None, 224, 224, 3), but it was re-called on a Tensor with incompatible shape (1, 244, 244, 3).\n",
      "\n",
      "J_style = 1258364511512.917\n"
     ]
    }
   ],
   "source": [
    "coefs = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "J_style = compute_style_cost(style_input, generated_input, style_layers, coefs)\n",
    "print(\"\\nJ_style = \" + str(J_style.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_total = 12583648829282.305\n"
     ]
    }
   ],
   "source": [
    "J_total = total_cost(J_content, J_style)\n",
    "print(\"J_total = \" + str(J_total.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit",
   "language": "python",
   "name": "python36364bit4ec56d622a534a5daaf9586f2862688a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
